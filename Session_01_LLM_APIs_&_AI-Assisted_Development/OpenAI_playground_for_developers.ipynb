{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPtFBgj623FS"
      },
      "source": [
        "# Developing with OpenAI: AIM Edition\n",
        "\n",
        "## Exploring LLM Prompting Strategies for Economic Reasoning  \n",
        "### *Inflation & Interest Rate Case Study*\n",
        "\n",
        "This notebook investigates how different prompting strategies (zero-shot, few-shot, reasoning vs non-reasoning models) affect the ability of large language models (LLMs) to reason about inflation, interest rates, and overall market dynamics.  \n",
        "\n",
        "We also retain all the previous instructional structure and code scaffolding to maintain a complete, comprehensive educational example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w4egfB274VD"
      },
      "source": [
        "## 1. Getting Started\n",
        "\n",
        "The first thing we'll do is load the [OpenAI Python Library](https://github.com/openai/openai-python/tree/main)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23H7TMOM4mfy",
        "outputId": "698578e4-f787-41d6-fe93-249b8af78b9a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'activate (Python 3.13.7)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/roberra/Documents/ai_eng/code/AIEO1-Rob/Session_01_LLM_APIs_&_AI-Assisted_Development/activate/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Used for Google Colab\n",
        "#!pip install openai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Discussion and Problem Framing\n",
        "\n",
        "We aim to answer:  \n",
        "> *\"What is the best prompting approach and model type to understand how the market is performing today?\"*  \n",
        "\n",
        "### Types of LLM Tasks Involved\n",
        "\n",
        "| Type | Description | Example Output |\n",
        "|------|--------------|----------------|\n",
        "| **Retrieval** | Factual recall | ‚ÄúInflation in 2025 is around 3.1% in the U.S.‚Äù |\n",
        "| **Reasoning** | Logical chain between variables | ‚ÄúHigher inflation led the Fed to raise rates ‚Üí borrowing costs rose ‚Üí slower GDP.‚Äù |\n",
        "| **Generation** | Narrative creation / summary | ‚ÄúThe market shows cooling signals despite moderate inflation‚Ä¶‚Äù |\n",
        "\n",
        "Each prompt and model will be evaluated on reasoning depth, factual correctness, and structure quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Used models in this repo\n",
        "\n",
        "| Rank | Model Name | Primary Purpose | OpenAI's Official Claim |\n",
        "|------|------------|-----------------|------------------------|\n",
        "| 1 | **GPT-5** | Advanced reasoning for complex economic analysis | Uses a dynamic router that chooses between quick responses and deeper 'thinking' when needed; performs at PhD-level across domains |\n",
        "| 2 | **GPT-4.1** | Enhanced coding and long-context comprehension | Offers significant advancements in coding capabilities, long context comprehension (up to 1M tokens), and instruction following |\n",
        "| 3 | **GPT-4-turbo** | General-purpose non-reasoning model for structured responses | Improved version of GPT-4 with enhanced performance, lower latency, and updated knowledge cutoff |\n",
        "| 4 | **GPT-4o-mini** | Fast, efficient model for quick responses | Cost-efficient AI model designed to make advanced AI technology more affordable and accessible |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKD8XBTVEAOw"
      },
      "source": [
        "## 2. Setting Environment Variables\n",
        "\n",
        "As we'll frequently use various endpoints and APIs hosted by others - we'll need to handle our \"secrets\" or API keys very often.\n",
        "\n",
        "We'll use the following pattern throughout this bootcamp - but you can use whichever method you're most familiar with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGU9OMvhEPG0",
        "outputId": "2609c2ff-e2f5-4464-fb26-38a4fcfe7ea3"
      },
      "outputs": [],
      "source": [
        "# For Google Colab\n",
        "# import os\n",
        "# import getpass\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For local development\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dabxI3MuEYXS"
      },
      "source": [
        "## 3. Using the OpenAI Python Library\n",
        "\n",
        "Let's jump right into it!\n",
        "\n",
        "> NOTE: You can, and should, reference OpenAI's [documentation](https://platform.openai.com/docs/api-reference/authentication?lang=python) whenever you get stuck, have questions, or want to dive deeper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbCbNzPVEmJI"
      },
      "source": [
        "### Creating a Client\n",
        "\n",
        "The core feature of the OpenAI Python Library is the `OpenAI()` client. It's how we're going to interact with OpenAI's models, and under the hood of a lot what we'll touch on throughout this course.\n",
        "\n",
        "> NOTE: We could manually provide our API key here, but we're going to instead rely on the fact that we put our API key into the `OPENAI_API_KEY` environment variable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LNwZtaE-EltC"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDxUkDbFBPI"
      },
      "source": [
        "### Using the Client\n",
        "\n",
        "Now that we have our client - we're going to use the `.chat.completions.create` method to interact with the model.\n",
        "\n",
        "There's a few things we'll get out of the way first, however, the first being the idea of \"roles\".\n",
        "\n",
        "First it's important to understand the object that we're going to use to interact with the endpoint. It expects us to send an array of objects of the following format:\n",
        "\n",
        "```python\n",
        "{\"role\" : \"ROLE\", \"content\" : \"YOUR CONTENT HERE\", \"name\" : \"THIS IS OPTIONAL\"}\n",
        "```\n",
        "\n",
        "Second, there are three \"roles\" available to use to populate the `\"role\"` key:\n",
        "\n",
        "- `system`\n",
        "- `assistant`\n",
        "- `user`\n",
        "\n",
        "OpenAI provides some context for these roles [here](https://help.openai.com/en/articles/7042661-moving-from-completions-to-chat-completions-in-the-openai-api).\n",
        "\n",
        "We'll explore these roles in more depth as they come up - but for now we're going to just stick with the basic role `user`. The `user` role is, as it would seem, the user!\n",
        "\n",
        "Thirdly, it expects us to specify a model!\n",
        "\n",
        "We'll use the `gpt-5-mini` model as stated above.\n",
        "\n",
        "Let's look at an example!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2RpNl6yNGzb0"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc_UbpwNHdrM"
      },
      "source": [
        "Let's look at the response object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsXJtvxRHfoM",
        "outputId": "3b28ce47-a765-4446-b0f9-33738e385b96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-Cce2pmPXv2snC9BmIb3TwqVNxi5Pj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1763326431, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=8, total_tokens=26, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy9kSuf1Hiv5"
      },
      "source": [
        ">NOTE: We'll spend more time exploring these outputs later on, but for now - just know that we have access to a tonne of powerful information!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDZ8gjiAISyd"
      },
      "source": [
        "### System Role\n",
        "\n",
        "Now we can extend our prompts to include a system prompt.\n",
        "\n",
        "The basic idea behind a system prompt is that it can be used to encourage the behaviour of the LLM, without being something that is directly responded to - let's see it in action!\n",
        "\n",
        "In the newest OpenAI API, the **system message** still defines the model‚Äôs behavior.  \n",
        "Sometimes it is referred to as an *instruction block*.\n",
        "\n",
        "Example system prompt for our economics case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are an experienced economic analyst explaining how inflation and interest rates interact.   \n",
            "Use 2025 U.S. market context when relevant.\n",
            "Your answer should not exceed 5 sentences. \n",
            "\n",
            "What is the relationship between inflation and interest rates?\n",
            "Inflation and interest rates generally exhibit a direct relationship where rising inflation typically leads to increased interest rates and vice versa. Central banks, such as the Federal Reserve in the U.S., often raise interest rates to manage or curb high inflation by making borrowing more expensive, which can dampen spending and investment, helping to slow the economy and reduce inflationary pressures. Conversely, in a low inflation environment, central banks may lower interest rates to stimulate borrowing and investment, thereby boosting economic activity. As of 2025, the U.S. may see variable interest rate adjustments responding to both domestic economic conditions and global economic shifts, reflecting the central bank's ongoing efforts to stabilize prices while promoting sustainable economic growth. This delicate balance aims to maintain inflation within a target range, typically around 2%, to ensure economic stability and predictability.\n"
          ]
        }
      ],
      "source": [
        "system_prompt_text = \"\"\"\n",
        "You are an experienced economic analyst explaining how inflation and interest rates interact.   \n",
        "Use 2025 U.S. market context when relevant.\n",
        "Your answer should not exceed 5 sentences. \n",
        "\"\"\"\n",
        "print(system_prompt_text)\n",
        "\n",
        "user_prompt_text = \"What is the relationship between inflation and interest rates?\"\n",
        "print(user_prompt_text)\n",
        "\n",
        "list_of_prompts = [\n",
        "\n",
        "    {\"role\": \"system\", \"content\": system_prompt_text},\n",
        "    {\"role\": \"user\", \"content\": user_prompt_text}\n",
        "]\n",
        "\n",
        "irate_response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print(irate_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpyVhotWIsOs"
      },
      "source": [
        "As you can see - the response we get back is very much in line with the system prompt!\n",
        "\n",
        "Let's try the same user prompt, but with a different system to prompt to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "2coVmMn3I0-2",
        "outputId": "571b89a2-9209-4003-d63c-49b653e0d56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are a cool and fun elementary teacher explaining to 6-year olds how inflation and interest rates interact.   \n",
            "Use 2025 U.S. market context when relevant.\n",
            "Your answer should not exceed 5 sentences.\n",
            "\n",
            "What is the relationship between inflation and interest rates?\n",
            "Alright kids, imagine you have a piggy bank where you save your allowance. If prices of toys go up (that's what we call inflation), your money buys less. So, the bank offers you more candy (interest) to save your money there; that's the interest rate going up. When the bank gives more candy, it helps keep the price of toys from going too fast. Just like in 2025, when prices start to climb, banks might give more candy to help everyone buy what they need without prices going too crazy!\n"
          ]
        }
      ],
      "source": [
        "system_prompt_text = \"\"\"\n",
        "You are a cool and fun elementary teacher explaining to 6-year olds how inflation and interest rates interact.   \n",
        "Use 2025 U.S. market context when relevant.\n",
        "Your answer should not exceed 5 sentences.\n",
        "\"\"\"\n",
        "print(system_prompt_text)\n",
        "\n",
        "user_prompt_text = \"What is the relationship between inflation and interest rates?\"\n",
        "print(user_prompt_text)\n",
        "\n",
        "list_of_prompts = [\n",
        "\n",
        "    {\"role\": \"system\", \"content\": system_prompt_text},\n",
        "    {\"role\": \"user\", \"content\": user_prompt_text}\n",
        "]\n",
        "\n",
        "irate_response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print(irate_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e13heYNQJAo-"
      },
      "source": [
        "With a simple modification of the system prompt - you can see that we got completely different behaviour, and that's the main goal of prompt engineering as a whole.\n",
        "\n",
        "Also, congrats, you just engineered your first prompt!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VI3zlPJL05"
      },
      "source": [
        "### Few-shot Prompting\n",
        "\n",
        "Now that we have a basic handle on the `system` role and the `user` role - let's examine what we might use the `assistant` role for.\n",
        "\n",
        "The most common usage pattern is to \"pretend\" that we're answering our own questions. This helps us further guide the model toward our desired behaviour. While this is a over simplification - it's conceptually well aligned with few-shot learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "lwxPuCyyJMye",
        "outputId": "ec01213d-6755-4506-8879-cf0870934349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zero-shot response: Inflation plays a significant role in influencing interest rate decisions made by central banks, such as the Federal Reserve in the United States or the European Central Bank in the Eurozone. Here‚Äôs how the dynamics work:\n",
            "\n",
            "1. **Monetary Policy Goal**: One of the primary objectives of central banks is to maintain price stability. This often means keeping inflation within a target range (commonly around 2% in many developed economies). \n",
            "\n",
            "2. **Inflation Rate Changes**: When inflation rises above the central bank's target, it erodes the purchasing power of money. This can lead to concerns about an overheating economy and can prompt central banks to take action to cool it down.\n",
            "\n",
            "3. **Interest Rate Adjustment**: \n",
            "   - **Raising Rates**: To combat high inflation, central banks often increase interest rates. Higher rates can discourage borrowing and spending by consumers and businesses, which can help to reduce demand in the economy and, in turn, lower inflation. This is because as borrowing costs rise, both consumers and businesses are less likely to take out loans or engage in large expenditures.\n",
            "   - **Lowering Rates**: Conversely, when inflation is low or there are threats of deflation, central banks may lower interest rates to stimulate economic activity. Lowering rates makes borrowing cheaper, encouraging spending and investment, which can help to boost demand and potentially raise inflation towards the target range.\n",
            "\n",
            "4. **Real vs. Nominal Interest Rates**: It‚Äôs important to distinguish between nominal interest rates (the stated rate) and real interest rates (nominal interest rate adjusted for inflation). If inflation is high, real interest rates can be low or even negative, which can distort economic decisions made by consumers and businesses. Central banks monitor both to gauge the true cost of borrowing and the effectiveness of their monetary policy.\n",
            "\n",
            "5. **Market Expectations**: Central banks also consider market expectations of future inflation when making interest rate decisions. If people and businesses expect higher inflation in the future, they may act accordingly (e.g., demanding higher wages or increasing prices). This can create a self-fulfilling prophecy, leading central banks to take pre-emptive measures on interest rates.\n",
            "\n",
            "6. **Communication and Forward Guidance**: Central banks often communicate their intentions regarding interest rate changes to guide market expectations. Clear communication can help stabilize financial markets and manage inflation expectations.\n",
            "\n",
            "7. **Long-term Policy Considerations**: While immediate inflation trends will influence current interest rate decisions, central banks also consider longer-term economic indicators and potential future inflation scenarios, leading to a more nuanced approach to interest rate setting.\n",
            "\n",
            "In summary, inflation significantly impacts how central banks set interest rates, shaping decisions aimed at maintaining economic stability and ensuring that inflation remains within desired levels. Balancing inflation control and economic growth is a continual challenge for policymakers.\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot prompt\n",
        "prompt_zero = \"Explain how inflation affects interest rate decisions.\"\n",
        "list_of_prompts = [\n",
        "    {\"role\": \"user\", \"content\": prompt_zero}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print('zero-shot response:', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "few-shot response: A: Inflation starts to sizzle like a hot skillet üç≥‚Äî when prices rise too quickly, the central bank might crank up interest rates to cool things down. Higher rates make loans pricier, so folks spend less and save more, helping to bring inflation back in check and stabilize the economic buffet.\n"
          ]
        }
      ],
      "source": [
        "# Few-shot prompt template\n",
        "\n",
        "question = \"Explain how inflation affects interest rate decisions.\"\n",
        "\n",
        "few_shot_prompt = f\"\"\"\n",
        "Example 1:\n",
        "Q: The price of pizza slices jumps from $2 to $4. What might the central bank do?\n",
        "A: They turn down the oven heat üçïüî• ‚Äî raise interest rates so people buy fewer slices and cool off the price party.\n",
        "\n",
        "Example 2:\n",
        "Q: Interest rates drop and borrowing gets cheaper. What happens at Snack City?\n",
        "A: Everyone's grabbing extra fries and milkshakes üçüü•§‚Äî cheap credit means more spending, which can make prices rise again.\n",
        "\n",
        "Now answer:\n",
        "Q: {question}\n",
        "\"\"\"\n",
        "\n",
        "list_of_prompts = [\n",
        "    {\"role\": \"user\", \"content\": few_shot_prompt}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print('few-shot response:', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions\n",
        "\n",
        "We're going to create some helper functions to aid in using the OpenAI API - just to make our lives a bit easier.\n",
        "\n",
        "> NOTE: Take some time to understand these functions between class!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def get_response(client: OpenAI, messages: list, model: str = \"gpt-4o-mini\") -> str:\n",
        "    return client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "def system_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"system\", \"content\": message}\n",
        "\n",
        "def assistant_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"assistant\", \"content\": message}\n",
        "\n",
        "def user_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"user\", \"content\": message}\n",
        "\n",
        "def pretty_print(message: str) -> str:\n",
        "    display(Markdown(message.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgTVkNmOJQSC"
      },
      "source": [
        "Different way we can do prompting -> using the helper's functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "eEZkRJq5JQkQ",
        "outputId": "22170b9c-6212-42de-8469-a7efc9c9405d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It's like a dating coach giving you confidence boosters ‚Äî flooding the market with money to encourage spending and invest in relationships (assets) to revive the economy and spark romance (growth).\n"
          ]
        }
      ],
      "source": [
        "# Now, show the economic example with both user and assistant prompts\n",
        "few_shot_prompts = [\n",
        "    user_prompt(\"Inflation rises fast. How does the central bank react ‚Äî dating analogy please!\"),\n",
        "    assistant_prompt(\"They play hard to get ‚Äî raise rates ‚Äî to cool off the economy's over-eager spending habits.\"),\n",
        "\n",
        "    user_prompt(\"What happens when interest rates are too low for too long?\"),\n",
        "    assistant_prompt(\"Everyone gets too comfortable ‚Äî too many relationships (loans) form, and eventually hearts (bubbles) break.\"),\n",
        "\n",
        "    user_prompt(\"Explain deflation using a dating metaphor.\"),\n",
        "    assistant_prompt(\"No one's asking anyone out ‚Äî everyone waits for a better deal, so the economy gets lonely and quiet.\"),\n",
        "    # üëá Here's the actual question we want the model to answer\n",
        "    user_prompt(\"Describe quantitative easing\")\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=few_shot_prompts\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üèóÔ∏è Activity #1:\n",
        "Mission:\n",
        "Experiment with how different prompt structures, system, user, and assistant, plus zero-shot and few-shot prompting, can transform an AI‚Äôs response.\n",
        "Your goal: craft the most effective prompt and see how GPT-4-Turbo reacts!\n",
        "\n",
        "You‚Äôll test how GPT-4-Turbo behaves under four different setups:\n",
        "1. System/User roles only (Zero-shot)\n",
        "2. System/User roles + examples (Few-shot)\n",
        "3. No system role at all (User only)\n",
        "4. Creative system prompt twist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ACTIVITY 1: Prompt Structure Experimentation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Goal: Explaning relationship why inflation and interest rates matter to an elderly non-financial audience as part of a finance app\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Experiment 1: System/User roles only (Zero-shot)\u001b[39;00m\n\u001b[32m      5\u001b[39m few_shot_prompts = [\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43msystem_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a financial advisor helping explain financial concepts to the elderly and why they should care about it and how to act on it, specifically keeping in mind they are either near or in retirement. They have retirement savings through you, a financial management company similar to Vangaurd called Sunguard\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m      7\u001b[39m     user_prompt(\u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m'\u001b[39m\u001b[33mve been hearing a lot about interest rates, what is that\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m ]\n\u001b[32m     10\u001b[39m response = client.chat.completions.create(\n\u001b[32m     11\u001b[39m     model = \u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     messages = few_shot_prompts\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
            "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
          ]
        }
      ],
      "source": [
        "# ACTIVITY 1: Prompt Structure Experimentation\n",
        "# Goal: Explaning relationship why inflation and interest rates matter to an elderly non-financial audience as part of a finance app\n",
        "\n",
        "# Experiment 1: System/User roles only (Zero-shot)\n",
        "few_shot_prompts = [\n",
        "    system_prompt(\"You are a financial advisor helping explain financial concepts to the elderly and why they should care about it and how to act on it, specifically keeping in mind they are either near or in retirement. They have retirement savings through you, a financial management company similar to Vangaurd called Sunguard\"),\n",
        "    user_prompt(\"I've been hearing a lot about interest rates, what is that\")\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o\",\n",
        "    messages = few_shot_prompts\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "# Experiment 2: System/User roles + examples (Few-shot)\n",
        "\n",
        "# Experiment 3: No system role at all (User only)\n",
        "\n",
        "# Experiment 4: Creative system prompt twist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJGaLYM3JU-8"
      },
      "source": [
        "### Chain of Thought Prompting\n",
        "\n",
        "We'll head one level deeper and explore the world of Chain of Thought prompting (CoT).\n",
        "\n",
        "This is a process by which we can encourage the LLM to handle slightly more complex tasks.\n",
        "\n",
        "Let's look at a simple reasoning based example without CoT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ltLtF4wEJTyK",
        "outputId": "29c6e20f-edf1-4dfc-de8a-a8410f31b721"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m reasoning_problem = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mThe central bank increases the policy rate by 1.5 pp in response to 5 \u001b[39m\u001b[38;5;132;01m% i\u001b[39;00m\u001b[33mnflation while nominal wage growth is 3 \u001b[39m\u001b[33m%\u001b[39m\u001b[33m.\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mWhat happens to real wages?\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m list_of_prompts = [\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43muser_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreasoning_problem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m ]\n\u001b[32m     10\u001b[39m reasoning_response = get_response(client, list_of_prompts)\n\u001b[32m     11\u001b[39m pretty_print(reasoning_response)\n",
            "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
          ]
        }
      ],
      "source": [
        "reasoning_problem = \"\"\"\n",
        "The central bank increases the policy rate by 1.5 pp in response to 5 % inflation while nominal wage growth is 3 %.\n",
        "What happens to real wages?\n",
        "\"\"\"\n",
        "\n",
        "list_of_prompts = [\n",
        "    user_prompt(reasoning_problem)\n",
        "]\n",
        "\n",
        "reasoning_response = get_response(client, list_of_prompts)\n",
        "pretty_print(reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbqj30CQJnQl"
      },
      "source": [
        "Let's see if we can leverage a simple CoT prompt to improve our model's performance on this task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "A9Am3QNGJXHR",
        "outputId": "83b87232-911c-4ab9-a863-58ecfd10b8a9"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "When the central bank increases the policy rate by 1.5 pp in response to 5% inflation, it is trying to combat the rising prices by tightening monetary policy. This increase in the policy rate will lead to higher borrowing costs for businesses and individuals, which can slow down economic activity and reduce aggregate demand.\n",
              "\n",
              "As a result, businesses may not be able to afford to pay higher wages due to the higher borrowing costs and lower demand for their products/services. This can lead to slower growth in nominal wages, despite the fact that inflation is rising.\n",
              "\n",
              "In this scenario, nominal wage growth is 3%, while inflation is 5%. This means that real wages are actually decreasing, as the purchasing power of wages is being eroded by inflation. Real wages are calculated by adjusting nominal wages for changes in the price level.\n",
              "\n",
              "So, in this case, the real wage effect would be negative - despite workers receiving a 3% increase in wages, their purchasing power has decreased by more than that due to the 5% inflation rate. This highlights the importance of considering both nominal wages and inflation when assessing changes in real wages."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    user_prompt(reasoning_problem + \"Think step-by-step about how nominal wages, prices, and interest rates interact through the labor market and aggregate demand. Then explain the real wage effect.\")\n",
        "]\n",
        "\n",
        "reasoning_response = get_response(client, list_of_prompts)\n",
        "pretty_print(reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Running Comparative Experiment\n",
        "\n",
        "We'll test combinations of model type (reasoning vs non-reasoning) and prompting style (zero-shot vs few-shot).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 1: GPT-4-turbo (Non-Reasoning)\n",
            "==============================\n",
            "\n",
            "Zero-Shot Prompting (no examples):\n",
            "\n",
            "A: Inflation erodes the purchasing power of money, meaning that if nominal wages (the face value of wages paid) do not increase at the same rate as inflation, real wages (the purchasing power of those wages) will decline. Essentially, if inflation rises faster than nominal wages, workers can buy less with their earnings, resulting in a decrease in real income and living standards. This can impact consumer spending, savings rates, and overall economic growth. Conversely, if nominal wages increase faster than inflation, real wages rise, enhancing purchasing power and potentially boosting economic activity. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# üß© Comparing GPT Models: Reasoning vs Non-Reasoning\n",
        "# --------------------------------------------------\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "system_prompt_text = \"\"\"\n",
        "You are an experienced economic analyst.\n",
        "\"\"\"\n",
        "\n",
        "question = \"\"\"What is the impact of inflation on real wages? Respond in a concise manner.\"\"\"\n",
        "\n",
        "prompt_few = f\"\"\"\n",
        "Use this exact format to answer the question:\n",
        "Example 1:\n",
        "{{\n",
        "  \"possible_explanation\": \"Wage catch-up effect\",\n",
        "  \"mechanism\": \"Workers negotiate higher nominal wages to preserve purchasing power as prices rise.\",\n",
        "  \"impact_on_wages\": \"Nominal wages increase roughly in line with inflation, keeping real wages stable in the short run.\",\n",
        "  \"time_frame\": \"Short to medium run\",\n",
        "  \"economic_context\": \"Inflationary periods with strong labor bargaining power or cost-of-living adjustments.\"\n",
        "}}\n",
        "\n",
        "Example 2:\n",
        "{{\n",
        "  \"possible_explanation\": \"Real wage erosion\",\n",
        "  \"mechanism\": \"When nominal wages lag behind price growth, workers lose purchasing power.\",\n",
        "  \"impact_on_wages\": \"Real wages decline despite nominal wage increases, reducing workers‚Äô living standards.\",\n",
        "  \"time_frame\": \"Immediate term\",\n",
        "  \"economic_context\": \"High inflation environments with weak wage indexation or rigid labor contracts.\"\n",
        "}}\n",
        "\n",
        "Now answer:\n",
        "Q: {question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# MODEL 1: GPT-4-turbo  ‚Üí Non-Reasoning\n",
        "# --------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 1: GPT-4-turbo (Non-Reasoning)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Zero-shot\n",
        "answer_nonreasoning_zero_shot = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt_text},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ],\n",
        ")\n",
        "print(\"Zero-Shot Prompting (no examples):\\n\")\n",
        "print(\"A:\", answer_nonreasoning_zero_shot.choices[0].message.content, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 2: GPT-5 (Reasoning-Tuned)\n",
            "==============================\n",
            "\n",
            "Zero-Shot Prompting (no examples):\n",
            "\n",
            "A: - Real wages are nominal wages adjusted for prices; roughly, real wage growth ‚âà nominal wage growth ‚àí inflation.\n",
            "- If inflation exceeds nominal wage growth, purchasing power falls; if nominal wages grow faster, it rises.\n",
            "- Because wages adjust with lags and many aren‚Äôt fully indexed, unexpected inflation typically cuts real wages in the short run; COLAs/strong bargaining mitigate, while fixed-pay/minimum-wage workers lose more.\n",
            "- Non-indexed tax brackets (bracket creep) can further reduce after‚Äëtax real wages; over time, productivity growth is the key driver of sustained real wage gains. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# MODEL 2: GPT-5  ‚Üí Reasoning\n",
        "# --------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 2: GPT-5 (Reasoning-Tuned)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Zero-shot\n",
        "answer_reasoning_zero_shot = client.chat.completions.create(\n",
        "    model=\"gpt-5\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt_text},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ],\n",
        ")\n",
        "print(\"Zero-Shot Prompting (no examples):\\n\")\n",
        "print(\"A:\", answer_reasoning_zero_shot.choices[0].message.content, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 1: GPT-4-turbo (Non-Reasoning)\n",
            "==============================\n",
            "\n",
            "Few-Shot Prompting (with examples):\n",
            "\n",
            "A: {\n",
            "  \"possible_explanation\": \"Inflation and real wage dynamics\",\n",
            "  \"mechanism\": \"Inflation reduces the purchasing power of nominal wages unless they are adjusted at the same rate or faster.\",\n",
            "  \"impact_on_wages\": \"Real wages decline if wage increases do not keep pace with inflation, eroding worker purchasing power.\",\n",
            "  \"time_frame\": \"Can be immediate or gradual, depending on inflation rate and wage adjustment frequency.\",\n",
            "  \"economic_context\": \"Periods of sustained inflation without corresponding and timely wage adjustments.\"\n",
            "} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 1: GPT-4-turbo (Non-Reasoning)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Few-shot\n",
        "answer_nonreasoning_few_shot = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt_text},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ],\n",
        ")\n",
        "print(\"Few-Shot Prompting (with examples):\\n\")\n",
        "print(\"A:\", answer_nonreasoning_few_shot.choices[0].message.content, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 2: GPT-5 (Reasoning-Tuned)\n",
            "==============================\n",
            "\n",
            "Few-Shot Prompting (with examples):\n",
            "\n",
            "A: {\n",
            "  \"possible_explanation\": \"Real wage erosion\",\n",
            "  \"mechanism\": \"If nominal wage growth trails inflation, purchasing power falls.\",\n",
            "  \"impact_on_wages\": \"Real wages decline until nominal wages catch up.\",\n",
            "  \"time_frame\": \"Immediate to short run\",\n",
            "  \"economic_context\": \"High or accelerating inflation with limited wage indexation or weak bargaining power.\"\n",
            "} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 2: GPT-5 (Reasoning-Tuned)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Few-shot\n",
        "answer_reasoning_few_shot = client.chat.completions.create(\n",
        "    model=\"gpt-5\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt_text},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ],\n",
        ")\n",
        "print(\"Few-Shot Prompting (with examples):\\n\")\n",
        "print(\"A:\", answer_reasoning_few_shot.choices[0].message.content, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. Evaluation Framework\n",
        "\n",
        "LLM as a judge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Parsed JSON Result:\n",
            "{\n",
            "  \"Answer A Score\": 4,\n",
            "  \"Answer B Score\": 3,\n",
            "  \"Better Answer\": \"A\",\n",
            "  \"Explanation\": \"Both answers are factually correct: inflation reduces real wages if nominal wages do not rise as fast. Answer A is slightly better reasoned and more complete \\u2014 it notes the role of timely wage adjustments and allows for immediate or gradual effects depending on inflation rate and adjustment frequency, capturing the key interdependency between inflation and wage-setting. Answer B is accurate but narrower (emphasizing the short run) and omits the explicit role of adjustment timing that A highlights, so it receives a lower score.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# --------------------------------------------------\n",
        "# ‚öñÔ∏è LLM-as-a-Judge Evaluation Script\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Define evaluation scale (0‚Äì4)\n",
        "# 0 = completely incorrect / irrelevant\n",
        "# 1 = partially correct but weak or inaccurate reasoning\n",
        "# 2 = fair factual accuracy, minimal reasoning\n",
        "# 3 = accurate and somewhat reasoned\n",
        "# 4 = highly accurate, clear causal explanation, correct logic\n",
        "\n",
        "evaluation_prompt = f\"\"\"\n",
        "You are an impartial economics teacher grading two student answers to the same question.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer A (non-reasoning model):\n",
        "{answer_nonreasoning_few_shot.choices[0].message.content}\n",
        "\n",
        "Answer B (reasoning model):\n",
        "{answer_reasoning_few_shot.choices[0].message.content}\n",
        "\n",
        "Evaluate both answers on accuracy and reasoning quality on a 0‚Äì4 scale:\n",
        "- 0 = completely incorrect or irrelevant\n",
        "- 1 = partially correct, but flawed\n",
        "- 2 = fair factual accuracy, limited reasoning\n",
        "- 3 = mostly correct, some reasoning\n",
        "- 4 = fully accurate and clearly reasoned, ability to see the interdependencies between variables.\n",
        "\n",
        "Return your evaluation as a JSON object in this exact format:\n",
        "{{\n",
        "  \"Answer A Score\": <0-4>,\n",
        "  \"Answer B Score\": <0-4>,\n",
        "  \"Better Answer\": \"A\" or \"B\",\n",
        "  \"Explanation\": \"Why the better answer is more accurate or reasoned\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# Choose a strong evaluator model (GPT-4.1 is good for judging)\n",
        "evaluation = client.chat.completions.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an impartial LLM evaluator for economics-related answers.\"},\n",
        "        {\"role\": \"user\", \"content\": evaluation_prompt}\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Parse and display the evaluation\n",
        "response_text = evaluation.choices[0].message.content\n",
        "\n",
        "# Optional: try to parse JSON for structured output\n",
        "try:\n",
        "    result = json.loads(response_text)\n",
        "    print(\"\\nParsed JSON Result:\")\n",
        "    print(json.dumps(result, indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\nNote: Could not parse JSON, model may have returned free text instead.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üèóÔ∏è Activity #2:\n",
        "\n",
        "Evaluate different prompting strategies using your own example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Reasoning model answer saved to: /Users/katerinag/Documents/AIE/on-ramp/Lesson1/results.md\n"
          ]
        }
      ],
      "source": [
        "# Create markdown content\n",
        "markdown_content = f\"\"\"\n",
        "# üß† Reasoning Model Answer\n",
        "### Question:\n",
        "How does inflation affect interest rates and the broader market?\n",
        "\n",
        "### Model Used:\n",
        "`gpt-4.1` (Reasoning-tuned)\n",
        "\n",
        "### Response:\n",
        "{answer_reasoning_few_shot.choices[0].message.content}\n",
        "\n",
        "---\n",
        "\n",
        "*This answer was generated by a reasoning model to illustrate step-by-step economic reasoning.*\n",
        "\"\"\"\n",
        "\n",
        "output_path='./results.md'\n",
        "# Save to file\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown_content)\n",
        "\n",
        "print(f\"‚úÖ Reasoning model answer saved to: {os.path.abspath(output_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "- **Few-shot prompts** improve structure and reasoning consistency.  \n",
        "- **Reasoning models** (like GPT-5-reasoning) deliver more coherent causal explanations between inflation, interest rates, and growth indicators.  \n",
        "- **Non-reasoning models** (e.g., GPT-5-mini) provide faster, surface-level insights ideal for retrieval or summarization tasks.  \n",
        "- Future work could add **RAG pipelines** with real-time macroeconomic data or integrate with financial dashboards for live LLM reasoning visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
